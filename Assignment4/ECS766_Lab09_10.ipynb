{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECS766_Lab09_10.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKNf2WkWpcWs",
        "colab_type": "text"
      },
      "source": [
        "# <font color='gray'> Lab 4: Dimensionality & Feature Selection</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nC6ZwWkQn3J4",
        "colab_type": "text"
      },
      "source": [
        "## Introduction \n",
        "\n",
        "\n",
        "The aim of this lab is familiarity with the concepts of **manipulating the dimensions (columns) of high dimensional data**, including **feature selection** and **dimensionality reduction**.\n",
        "- This lab manual runs over two weeks (*Week 9* and *Week 10*). \n",
        "- It is the **fourth assignment (worth 6%)**. **Exact deadline is on the submission link on QM+**.\n",
        "- Exercises in <font color = 'maroon'>**red**</font> are assessed towards your final grade."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4k8ZphQqATM",
        "colab_type": "text"
      },
      "source": [
        "## **1.  Feature Selection -- Weka**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbJCDUqSqc0Q",
        "colab_type": "text"
      },
      "source": [
        "**0. Open Weka and load the `Labor.arff` dataset.**\n",
        "\n",
        "*   This is about analysing potential contracts debated between unions and management according to whether they were accepted or rejected by the negotiating parties. This will be a useful model because contracts could be checked automatically for credibility before wasting time debating.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ-vL4qslIew",
        "colab_type": "text"
      },
      "source": [
        "**1. Select each of the five attributes in the explorer. The sixth is the class (label) itself.**\n",
        "\n",
        "*   Which attribute looks the most informative about the class (the colors=class in the histogram appear to overlap the least)? Which looks least informative about the class?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH_cHxVYle_k",
        "colab_type": "text"
      },
      "source": [
        "**2. Let's walk through *backward feature selection*.**\n",
        "\n",
        "* Start by running `Nearest Neighbour` classification (`Classifier` &rarr; `Lazy` &rarr; `IBk`). Make sure `10-fold` `cross-validation` is selected. Pay attention to the attributes used, and the classification accuracy.\n",
        "\n",
        "* Recall that backward feature selection, a **wrapper** method, greedily removes features to try and optimise the cross-validation accuracy.\n",
        "\n",
        "* Remove each of the five attributes in turn (Tick box & Remove on the Preprocess screen) and rerun the `NN` classifier. Take note of the classification accuracy with each attribute removed.\n",
        "\n",
        "> *Note that you can hit undo after each removal and classify. And note that you can review the list of results on the classify screen.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LF9DGhtNVBX",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "> **Q0:** Which attribute, when removed, gave the best accuracy?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVeaQTlONWEO",
        "colab_type": "text"
      },
      "source": [
        "> **A0:**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joJsdL7-Nkst",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "> **Q1:** This defines the best 4-attribute subset. What is it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eWjt5V9Npr9",
        "colab_type": "text"
      },
      "source": [
        "> **A1:**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZGF6HGOq2AU",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "#### <font color='maroon'>**Exercise 0:** Now starting from this 4-attribute subset, find the best 3, 2, 1 attribute subset, filling in the table below. Which sized subset, and which set of attributes yields the best accuracy? <ins>[1 mark]\n",
        "  \n",
        "  \n",
        "| Subset Size | Attributes Selected   | Accuracy | Attribs Removed |\n",
        "|-------------|-----------------------|----------|-----------------|\n",
        "| 5           | All: W, P, Hol, Vac, Health | 85.9% | None       |\n",
        "| 4           |                       |          |                 |\n",
        "| 3           |                       |          |                 |\n",
        "| 2           |                       |          |                 |\n",
        "| 1           |                       |          |                 |\n",
        "\n",
        "</ins></font>\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfR9ztzxQYqh",
        "colab_type": "text"
      },
      "source": [
        "* It is important to note that greedy feature selection does not try all combinations of features, so it may not find the absolute best combination."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGdKqrVAQeln",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "#### <font color='maroon'>**Exercise 1:** How many feature combinations did you try? How many combinations of features are there in total?  Give an example of a combination of features that you did NOT try when doing backward selection. [1 mark]</font>\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onLLoI43Q2KI",
        "colab_type": "text"
      },
      "source": [
        "**3. Now let's explore ways to automate the feature selection process.**\n",
        "\n",
        "* Go to Select Attributes. `Evaluator` &rarr; `Information Gain`. `Search` &rarr; `Ranker`.\n",
        "\n",
        "* This **filtering** method ranks each attribute by how much information they provide about the class (by estimating the *information gain* (the uncertainty in the label, minus the uncertainty in the label given the feature.))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIELu323SJ5a",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "> **Q2:** Which attribute was ranked the highest and which one the lowest? Did those correspond to the last one surviving and the first one eliminated in your backward selection?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QGBDajLSbr2",
        "colab_type": "text"
      },
      "source": [
        "> **A2:**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Voo98EzDSJlP",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "> **Q3:** Compare the results for Chi-squared (correlation based) ranking. Does it generally lead to the same attributes as with the Information Gain ranking?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iupfrU65SdgS",
        "colab_type": "text"
      },
      "source": [
        "> **A3:**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnOhU0HlSjtm",
        "colab_type": "text"
      },
      "source": [
        "* Now let's try to replicate the backward feature selection experiment. Select `Attribute Evaluator` &rarr; `WrapperSubset`, and `Search Method` &rarr; `GreedyStepwise`. \n",
        "\n",
        "  Set the `Attribute Evaluator` parameters (click on the box to the right of `Choose` under Attribute Evaluator): set it to use 10-fold Cross-Validation as in *Section 2* of this lab, and select `KNN` (`Lazy-IBk`) for the classifier. \n",
        "  \n",
        "  Set the Search method parameter (box to the right of `Choose` under Search Method): make sure backward feature selection is selected (`searchBackwards` &rarr; `True`).  \n",
        "  \n",
        "  Also make sure that `Attribute Selection Mode` box is set on *Use full training set*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoL4fzbtT9so",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "#### <font color='maroon'>**Exercise 2:** How many and which attributes are selected? Do they match the results from *Section 2*? <ins>[1 mark]</ins></font>\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RA2Vjq-XUQIX",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "> **Q4:** Now try forward selection (`Search Method options` &rarr; `SearchBackwards` &rarr; `False`). Are the same subset of attributes selected? If not, explain how is it possible for forward selection to result in a different answer than backward selection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmO2d0q2UWK_",
        "colab_type": "text"
      },
      "source": [
        "> **A4:**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWANIMADUsZH",
        "colab_type": "text"
      },
      "source": [
        "**4. Load the Iris flower type data (This is the same dataset we explored in Python in the previous lab, but now in Weka): `Open` &rarr; `iris.arff`)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4Zo8OKeRWGV",
        "colab_type": "text"
      },
      "source": [
        "* Run the `Naïve Bayes` classifier (`Classifier` &rarr; `Choose` &rarr;`Bayes` &rarr; `NaiveBayes`) and note the performance. \n",
        "\n",
        "  Also run the `logistic regression` classifier (`Classifier` &rarr; `Choose` &rarr; `Functions` &rarr; `Logistic`) and observe the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggf6SUGUP02J",
        "colab_type": "text"
      },
      "source": [
        "* Recall that one drawback of `Naïve Bayes` is that if the features' conditional independence assumption is not met, then performance may be compromised.\n",
        "\n",
        "  To observe this, make 3 copies each of `sepal length` and `sepal width`. To do this, under `Preprocess` tab, perform:\n",
        "> i. `Filter` &rarr; `Unsuperv.`&rarr; `Attribute` &rarr; `Copy`, and then for its parameters, set:`Index` &rarr; `1,2`, and finally click on `Apply`.<br>\n",
        ">ii. `Filter` &rarr; `Unsuperv.`&rarr; `Attribute` &rarr; `Copy`. Parameters: `Index` &rarr; `6,7`. `Apply`.<br>\n",
        ">iii. `Filter` &rarr; `Unsuperv.`&rarr; `Attribute` &rarr; `Copy`. Parameters: `Index`  &rarr; `8,9`. `Apply`. <br>\n",
        "\n",
        " Now our database has 11 columns instead of 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2UhkyPSWTTh",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "> **Q5:** Now re-try the classifiers `NaïveByes`, and `Logistic Regression`. (Make sure `class` is still set as the target attribute for the classifier). How do each of these classifiers perform?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0imKYIpsWWCo",
        "colab_type": "text"
      },
      "source": [
        "> **A5:**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YYueYSqWnaY",
        "colab_type": "text"
      },
      "source": [
        "* Now try to use the `Select attributes` tab to find the right attributes for `Naïve Bayes` given the modified dataset with redundant columns:\n",
        ">`Attribute Evaluator` &rarr; `WrapperSubsetEval`. \n",
        "\n",
        "  > Parameters: `Classifier` &rarr; `NaïveBayes`. \n",
        "\n",
        "  > `Search Method` &rarr; `GreedyStepwise`\n",
        "  \n",
        "  > Make sure the `class` is chosen as the target (label) of classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOMPUN7MXSP8",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "#### <font color='maroon'>**Exercise 3:** Which attributes does it pick (and hence which ones are discarded?) <ins>[1 mark]</ins></font>\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6FYmGNJWUAx",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "> **Q6:** Remove the rejected attributes and re-run `NaiveBayes` and `Logistic Regression` classifiers. How do they each perform now compared to the 11 column version, and to the initial four column version? What does this imply?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zubWmZGgWXn4",
        "colab_type": "text"
      },
      "source": [
        "> **A6:**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgbLOYNbun_k",
        "colab_type": "text"
      },
      "source": [
        "## **2. Dimensionality Reduction using PCA -- Python**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GpPnQGdC4wQ",
        "colab_type": "text"
      },
      "source": [
        "**1. Load the dataset**\n",
        "\n",
        "*   This first cell loads the `Yale_64x64` dataset, which is a face database. Details are here: http://vision.ucsd.edu/content/yale-face-database.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZGLOPEnDSem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "\n",
        "# load images from the mat file\n",
        "mat_contents = loadmat('Yale_64x64.mat')\n",
        "faces = mat_contents[\"fea\"]\n",
        "labels = mat_contents[\"gnd\"]\n",
        "\n",
        "print(faces.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ExIOvtmSgE6",
        "colab_type": "text"
      },
      "source": [
        "* The loaded face database is now in a numpy matrix called \"faces\". As you can see from its shape, it has 165 rows, and 4096 columns. \n",
        "Each row corresponds to a face image. Each column represents a (grayscale) pixel of the image. \n",
        "\n",
        "  Images are 64x64 pixles, so each row of our dataset has 4096 columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hi_IgvWwSOUb",
        "colab_type": "text"
      },
      "source": [
        "* We can display the images by *reshaping* each of the 1x4096 vectors to a 64x64 matrix. This can be done easily by using `np.reshape`, as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhjq_-b8S7WN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(15,15))\n",
        "\n",
        "for i in range(165):\n",
        "  img = np.reshape(faces[i,:], (64, 64)).T\n",
        "  ax = fig.add_subplot(15, 11, i+1)\n",
        "  plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
        "  ax.tick_params(labelleft=False, labelbottom=False)\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW1oaNpFVDHd",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "> **Q7:** Beside the `faces` variable, we also loaded a `labels` variable (whose size is 165x1). What information does it hold?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p75skgJsVRTD",
        "colab_type": "text"
      },
      "source": [
        "> **A7:**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCV87zBu2poC",
        "colab_type": "text"
      },
      "source": [
        "**2. Find a basis for the faces (eigenvectors of the covariance matrix).**\n",
        "\n",
        "The following cell takes the SVD (Singular Value Decomposition) of the data. The `U` output of the SVD is the eigenvectors of the\n",
        "data covariance required for PCA. These shows the basis vectors / prototype faces in terms of\n",
        "which all other faces are to be encoded (every face will be a linear combination of these\n",
        "prototypes). These constitute our principal components. Notice that some basis vectors encode lighting, others features such as glasses and mustache!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wat-N8AEy6yZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SVD gives Eigenvectors and Eigenvals:\n",
        "U, S, Vh = np.linalg.svd(faces.T, full_matrices=True) \n",
        "\n",
        "print(U.shape)\n",
        "\n",
        "# We also compute a picture in which each pixel is the \"average\" of that pixel \n",
        "# across all 165 images:\n",
        "meanFaces = np.mean(faces, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_1cKLCOvMa5",
        "colab_type": "text"
      },
      "source": [
        "Now let's plot the basis as well as the average face. \n",
        "Recall the interpretation of the principal components is the following: the first principal component explains the variations in the data the most, then the second one explains the remaining variance, and so on and so forth. We have only depicted the first 15 principal components. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwZgCdCd46zT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = np.reshape(meanFaces, (64, 64)).T\n",
        "fig = plt.figure(figsize=(15,15))\n",
        "fig.add_subplot(4, 4, 1)\n",
        "plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
        "plt.axis('off')\n",
        "\n",
        "  \n",
        "for image in range(15):\n",
        "  img = np.reshape(U[:, image], (64, 64)).T\n",
        "  fig.add_subplot(4, 4, image + 2)\n",
        "  plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I32d3kQH80Fb",
        "colab_type": "text"
      },
      "source": [
        "**3. PCA Encoding and Reconstruction.**\n",
        "\n",
        "* In the next cell, we are taking the PCA encoding of each face, and then decompress it back (reconstruct the image using only the first 25 principal components).\n",
        "\n",
        "* Recall that for a D-column input matrix/database, the goal of PCA is to construct a K < D\n",
        "column encoding that most accurately encodes the data in D.\n",
        "\n",
        "* You can see the original database `faces`, and the compressed database `pcaFaces`. You\n",
        "can compare their size with `faces.shape` and `pcaFaces.shape`. You can see the\n",
        "compressed version has only K=25 columns compared to the original D=4096 columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOtKBngm_lJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import linalg as LA\n",
        "import matplotlib.gridspec as gridspec\n",
        "from google.colab import widgets\n",
        "\n",
        "\n",
        "nPCA = 56 # how many pricipal components to use\n",
        "N = faces.shape[0] # the number of total images\n",
        "\n",
        "# PCA Encoding. Raw images (faces) => compressed images (pcaFaces).\n",
        "pcaFaces = np.matmul(U[:, 0:nPCA].T, faces.T - np.repeat(meanFaces, N).reshape(len(meanFaces), N))\n",
        "\n",
        "# PCA Decoding. Compressed images pcaFaces => Raw images reconstrFaces.\n",
        "reconstrFaces = np.matmul(U[:, 0:nPCA], pcaFaces) + np.repeat(meanFaces, N).reshape(len(meanFaces), N)\n",
        "\n",
        "\n",
        "grid = widgets.Grid(rows=4, columns=3)\n",
        "\n",
        "for row in range(4):\n",
        "  for col in range(3):\n",
        "    with grid.output_to(row, col):\n",
        "      fig = plt.figure(figsize=(5,5))\n",
        "      ax = fig.add_subplot(1, 2, 1)\n",
        "      image_index = row*3 + col + 1\n",
        "      img = np.reshape(faces[image_index * 10 - 1], (64, 64)).T\n",
        "      plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
        "      plt.xlabel('original')\n",
        "      ax.set_xticks([])\n",
        "      ax.set_yticks([])\n",
        "      ax.set_xticklabels([])\n",
        "      ax.set_yticklabels([])\n",
        "      \n",
        "      img = np.reshape(reconstrFaces[:, image_index * 10 - 1], (64, 64)).T\n",
        "      ax = fig.add_subplot(1,2,2)\n",
        "      plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
        "      plt.xlabel('reconstructed')\n",
        "      ax.set_xticks([])\n",
        "      ax.set_yticks([])\n",
        "      ax.set_xticklabels([])\n",
        "      ax.set_yticklabels([])\n",
        "\n",
        "\n",
        "\n",
        "print(faces.shape)\n",
        "print(pcaFaces.shape)\n",
        "\n",
        "print('original size: {} (KB)'.format(faces.size*8/1000))\n",
        "print('reduced size: {} (KB)'.format(pcaFaces.size*8/1000))\n",
        "error = LA.norm(reconstrFaces.flatten()-faces.T.flatten())**2/LA.norm(faces.flatten())**2\n",
        "print('Reconstruction error for nPCA={} is: {}'.format(nPCA, error))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1v-nYBgWAzL",
        "colab_type": "text"
      },
      "source": [
        "* Starting from 1 dimensional encoding, increase the dimensions (set variable `nPCA`) and re-run the cell, observing how the facial encoding fidelity increases. At what number of encoding dimensions can you see features like glasses and facial expression?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-wNNfbATHAg",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "> **Q8:** Following the above procedure, find out how many PCs (Principal Components) do you need to reach an encoding fidelity of 99%? (<1% reconstruction error). Compare the size in bytes of original and PCA data at this point.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoS0yjFdT1rg",
        "colab_type": "text"
      },
      "source": [
        "> **A8:**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sexvFPB3TLP4",
        "colab_type": "text"
      },
      "source": [
        "* Note that when using the full number (4096) of PCs, the encoding fidelity is 100%. Using all the PCs conveys exactly the same information as the original data. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FspkczEIb6Gw",
        "colab_type": "text"
      },
      "source": [
        "**4. Using eigenvalues:**\n",
        "\n",
        "The PCA process produces eigenvectors and eigenvalues. The eigenvectors give the new basis\n",
        "(i.e., define the new database columns), and the eigenvalues explain how useful each column is\n",
        "for encoding the data.*italicized text*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0uaMI-DcYmF",
        "colab_type": "text"
      },
      "source": [
        "* Let's look at the (square of the) eigenvalues of the basis:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-SYhXZ3ch1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eigvals = np.square(S)\n",
        "plt.plot(eigvals, linewidth=3)\n",
        "plt.grid()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5oT8fChckBW",
        "colab_type": "text"
      },
      "source": [
        "The x-axis is the new\n",
        "PCs/database dimension, and the Y-axis is the eigenvalue / information content.\n",
        "\n",
        "* The first few dimensions are by far the most informative.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz4o3paCf_h1",
        "colab_type": "text"
      },
      "source": [
        "Make this a cumulative plot to see how much of the overall variance is explained (encoded by) per each number of dimensions, i.e., how much each new dimension contributes to the reconstruction fidelity: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MrTfCPugeTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.cumsum(eigvals)/sum(eigvals))\n",
        "plt.plot(np.cumsum(eigvals)/sum(eigvals), linewidth=3)\n",
        "plt.xlabel('Dimensions')\n",
        "plt.ylabel('Reconstruction Accuracy')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKWhMwodWdL1",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "#### <font color='maroon'>**Exercise 4:** Use the data used to produce the above plot to find out what number of PCs is required to explain 99% of the data variance (achieve 99% reconstruction accuracy). What # is this and does it match the value from **Q8**? Provide a short discussion. <ins>[1 mark]</ins></font>\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiV7FU6Ui64H",
        "colab_type": "text"
      },
      "source": [
        "**5. Classification using reduced dimensions:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj7tL58OW-2o",
        "colab_type": "text"
      },
      "source": [
        "Now lets try to recognize the faces using a simple KNN classifier.\n",
        "* There are 15 people in this dataset. The following cell splits the data into train and test, and runs a 1-NN classifer on the test (using the train data):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZCpJqwVjHF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "nPCA = 4096 # how many pricipal components to use\n",
        "N = faces.shape[0] # the number of total images\n",
        "\n",
        "# PCA Encoding. Raw images (faces) => compressed images (pcaFaces).\n",
        "pcaFaces = np.matmul(U[:, 0:nPCA].T, faces.T - np.repeat(meanFaces, N).reshape(len(meanFaces), N))\n",
        "#pcaFaces = faces\n",
        "xTr = pcaFaces.T[::2,:]\n",
        "yTr = labels[::2]\n",
        "\n",
        "xTe = pcaFaces.T[1::2,:]\n",
        "yTe = labels[1::2]\n",
        "\n",
        "neigh = KNeighborsClassifier(n_neighbors=1).fit(xTr, yTr.ravel()) \n",
        "print('Accuracy score of 1-NN when nPCA = {} is {:.3f}'.format(nPCA, neigh.score(xTe,yTe)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlCPxvPJjJsd",
        "colab_type": "text"
      },
      "source": [
        "* Change nPCA. Observe that classification using different numbers of PCA dimensions\n",
        "produces different results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGdLjSRhWdxf",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "#### <font color='maroon'>**Exercise 5:** Which number of PCA dimensions gets the maximum face recognition accuracy? Is it better or worse than the accuracy when classifying the raw images? Why? (What factors contribute to this?) Provide a brief discussion.<ins> [1 mark]</ins></font>\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI6GM4Xlil6j",
        "colab_type": "text"
      },
      "source": [
        "* *Note: Accuracy was used in two different contexts in the above: (i) reconstruction accuracy (unsupervised learning task: How accurately an image is encoded after compressing away some of the columns with PCA) , and (ii) face recognition accuracy in the last task (Supervised learning task: How accurately can we recognize faces given raw image or PCA compressed image).*"
      ]
    }
  ]
}